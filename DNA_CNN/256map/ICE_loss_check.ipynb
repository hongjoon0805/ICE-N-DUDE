{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from core import *\n",
    "from tools import *\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/DNA_CNN/Denoising\n",
    "\n",
    "class ICE_Process:\n",
    "    def __init__(self, n, k, nb_x_classes, nb_z_classes, x, z, param_name = 'test'):\n",
    "        self.n, self.k, self.x, self.z, self.nb_x_classes, self.nb_z_classes = n, k, x, z, nb_x_classes, nb_z_classes\n",
    "        self.param_name = param_name\n",
    "        self.raw_error = error_rate(x,z)\n",
    "        self.C = make_batch(z,k)\n",
    "    \n",
    "    def Approximate_E_step(self, pred_prob): # approximate E-step & M-step\n",
    "        n, k, z, nb_x_classes, nb_z_classes = self.n, self.k, self.z, self.nb_x_classes, self.nb_z_classes\n",
    "        \n",
    "        \"\"\"\n",
    "        gamma[t][j] = p(x_t = j|Z_t,C_t;w)\n",
    "        \"\"\"\n",
    "        \n",
    "        # approximate E-step\n",
    "        \n",
    "        gamma = np.zeros((n, nb_x_classes))\n",
    "        for i in range(nb_x_classes):\n",
    "            gamma[:,i] = pred_prob[:,i+1]\n",
    "        gamma[np.arange(n), z] += pred_prob[np.arange(n), 0]\n",
    "        return gamma\n",
    "        \n",
    "    def M_step(self, pred_prob):\n",
    "        n, k, z, nb_x_classes, nb_z_classes = self.n, self.k, self.z, self.nb_x_classes, self.nb_z_classes\n",
    "        \n",
    "        gamma = self.Approximate_E_step(pred_prob)\n",
    "        \n",
    "        # M-step\n",
    "        PI = np.zeros((nb_x_classes, nb_z_classes))\n",
    "        np.add.at(PI.T, z, gamma)\n",
    "        PI /= (np.sum(gamma, axis = 0).reshape(nb_x_classes,1) + 1e-35)\n",
    "        return PI\n",
    "    \n",
    "    def ICE(self, PI, PI_true): # Iterative Channel Estimation Process\n",
    "        n, k, nb_x_classes, nb_z_classes, z, param_name, C = self.n, self.k, self.nb_x_classes, self.nb_z_classes, self.z, self.param_name, self.C\n",
    "        iteration = 10\n",
    "        \n",
    "        train_loss, val_loss = [], []\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            # reset the L_new matrix\n",
    "            L_new = L_NEW(PI, nb_x_classes, nb_z_classes)\n",
    "            Y = make_pseudo_label(C, k, L_new)\n",
    "            \n",
    "            L_new_true = L_NEW(PI_true, nb_x_classes, nb_z_classes)\n",
    "            Y_true = make_pseudo_label(C, k, L_new_true)\n",
    "            \n",
    "            model = NDUDE_CNN_model_5map(1000, nb_x_classes, nb_z_classes, k)\n",
    "            \n",
    "            # from second iteration, load previous weights and reset the learning rate.\n",
    "            if t!=0:\n",
    "                model.load_weights(\"weights/iteration/\"+param_name+\"_%d.hd5\"%(t-1))\n",
    "            \n",
    "            # model training...\n",
    "            hist = model.fit(C,Y,epochs=20, batch_size=2*4, verbose=1, validation_data=(C, Y_true))\n",
    "            pred_prob = model.predict(C, batch_size = 20*4, verbose = 0)\n",
    "            \n",
    "            train_loss.append(hist.history['loss'][-1])\n",
    "            val_loss.append(hist.history['val_loss'][-1])\n",
    "            \n",
    "            \n",
    "            # resize the output\n",
    "            N,D,_ = pred_prob.shape\n",
    "            pred_prob = np.resize(pred_prob, (N*D,5))[:n]\n",
    "            \n",
    "            # estimate the channel\n",
    "            PI = self.M_step(pred_prob)\n",
    "            \n",
    "            # save weights for next iteration\n",
    "            model.save_weights(\"weights/iteration/\"+param_name+\"_%d.hd5\"%(t))\n",
    "            \n",
    "            # save weights for denoising process\n",
    "            if t == iteration-1:\n",
    "                model.save_weights(\"weights/\"+param_name+\".hd5\")\n",
    "                save_PI(PI, param_name)\n",
    "        return PI, train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--k K] [--d D]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1002/jupyter/kernel-96920016-7bea-4ed9-a1aa-d4250d6a6dbd.json\n"
     ]
    }
   ],
   "source": [
    "PI_true = array([ [ 0.8122,  0.0034,  0.0894,  0.0950],\n",
    "                  [ 0.0096,  0.8237,  0.0808,  0.0859],\n",
    "                  [ 0.1066,  0.0436,  0.7774,  0.0724],\n",
    "                  [ 0.0704,  0.0690,  0.0889,  0.7717]])\n",
    "x, z = load_DNA(PI_true)\n",
    "\n",
    "try:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\"--k\", help=\"window size k\", type=int)\n",
    "    parser.add_argument(\"--d\", help=\"Assumed delta\", type=float)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    result_name = sys.argv[0]\n",
    "    k = args.k\n",
    "    assumed_delta = args.d\n",
    "    n = len(x)\n",
    "    param_name = \"ICE_%03d_%.2f\"%(k, assumed_delta)\n",
    "        \n",
    "except:\n",
    "    result_name = \"test\"\n",
    "    k = 150\n",
    "    assumed_delta = 0.40\n",
    "    n = int(1e4)\n",
    "    n = len(x)\n",
    "    param_name = \"test_%03d_%.2f\"%(k, assumed_delta)\n",
    "    \n",
    "nb_x_classes, nb_z_classes = 4, 4\n",
    "assumed_PI = sym_mat(4, assumed_delta)\n",
    "x, z = x[:n], z[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0, 1, 2, 3'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 150 assumed_delta: 0.40\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 9s 4ms/step - loss: 0.8793 - val_loss: 0.7494\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7953 - val_loss: 0.7345\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7693 - val_loss: 0.7287\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7557 - val_loss: 0.7250\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7470 - val_loss: 0.7195\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7411 - val_loss: 0.7199\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7370 - val_loss: 0.7193\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7337 - val_loss: 0.7168\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7309 - val_loss: 0.7165\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7286 - val_loss: 0.7170\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7268 - val_loss: 0.7174\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7252 - val_loss: 0.7136\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7240 - val_loss: 0.7114\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7229 - val_loss: 0.7116\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7220 - val_loss: 0.7127\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7210 - val_loss: 0.7127\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7201 - val_loss: 0.7112\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7195 - val_loss: 0.7129\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7191 - val_loss: 0.7120\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 3s 1ms/step - loss: 0.7185 - val_loss: 0.7117\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 5s 2ms/step - loss: 0.7808 - val_loss: 0.6811\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7790 - val_loss: 0.6813\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7783 - val_loss: 0.6802\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7780 - val_loss: 0.6798\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7776 - val_loss: 0.6795\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7772 - val_loss: 0.6801\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7769 - val_loss: 0.6792\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7766 - val_loss: 0.6791\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7763 - val_loss: 0.6784\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7760 - val_loss: 0.6784\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7759 - val_loss: 0.6786\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7756 - val_loss: 0.6790\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7753 - val_loss: 0.6784\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7752 - val_loss: 0.6783\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7750 - val_loss: 0.6777\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7747 - val_loss: 0.6772\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7746 - val_loss: 0.6774\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7745 - val_loss: 0.6773\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7743 - val_loss: 0.6775\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7741 - val_loss: 0.6773\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 5s 2ms/step - loss: 0.7422 - val_loss: 0.6805\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7419 - val_loss: 0.6822\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7417 - val_loss: 0.6816\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7416 - val_loss: 0.6797\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7415 - val_loss: 0.6804\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7412 - val_loss: 0.6802\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7410 - val_loss: 0.6799\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7410 - val_loss: 0.6805\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7408 - val_loss: 0.6799\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7407 - val_loss: 0.6802\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7406 - val_loss: 0.6799\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7405 - val_loss: 0.6805\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7404 - val_loss: 0.6801\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7402 - val_loss: 0.6807\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7401 - val_loss: 0.6798\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7400 - val_loss: 0.6795\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7399 - val_loss: 0.6792\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7398 - val_loss: 0.6793\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7397 - val_loss: 0.6799\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7397 - val_loss: 0.6788\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 2ms/step - loss: 0.7568 - val_loss: 0.6774\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7567 - val_loss: 0.6769\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7567 - val_loss: 0.6759\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7565 - val_loss: 0.6774\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7565 - val_loss: 0.6765\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7563 - val_loss: 0.6763\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7562 - val_loss: 0.6764\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7561 - val_loss: 0.6755\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7562 - val_loss: 0.6767\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7560 - val_loss: 0.6761\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7559 - val_loss: 0.6773\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7558 - val_loss: 0.6753\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7558 - val_loss: 0.6760\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7556 - val_loss: 0.6758\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7556 - val_loss: 0.6771\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7555 - val_loss: 0.6765\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7555 - val_loss: 0.6756\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7554 - val_loss: 0.6758\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7553 - val_loss: 0.6758\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7553 - val_loss: 0.6761\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 2ms/step - loss: 0.7400 - val_loss: 0.6779\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7396 - val_loss: 0.6771\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7396 - val_loss: 0.6777\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7396 - val_loss: 0.6769\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7395 - val_loss: 0.6760\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7395 - val_loss: 0.6772\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7393 - val_loss: 0.6767\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7392 - val_loss: 0.6760\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7392 - val_loss: 0.6760\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7392 - val_loss: 0.6772\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7391 - val_loss: 0.6777\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7390 - val_loss: 0.6778\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7390 - val_loss: 0.6767\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7389 - val_loss: 0.6766\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7390 - val_loss: 0.6755\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7388 - val_loss: 0.6765\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7387 - val_loss: 0.6773\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7388 - val_loss: 0.6757\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7386 - val_loss: 0.6760\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7386 - val_loss: 0.6766\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 2ms/step - loss: 0.7480 - val_loss: 0.6762\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7477 - val_loss: 0.6759\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7478 - val_loss: 0.6760\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7477 - val_loss: 0.6744\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7477 - val_loss: 0.6750\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7476 - val_loss: 0.6755\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7477 - val_loss: 0.6751\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7476 - val_loss: 0.6752\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7475 - val_loss: 0.6751\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7475 - val_loss: 0.6757\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7475 - val_loss: 0.6750\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7474 - val_loss: 0.6750\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7473 - val_loss: 0.6761\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7473 - val_loss: 0.6755\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7473 - val_loss: 0.6752\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7473 - val_loss: 0.6758\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7472 - val_loss: 0.6752\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7471 - val_loss: 0.6745\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7470 - val_loss: 0.6750\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7470 - val_loss: 0.6743\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 2ms/step - loss: 0.7254 - val_loss: 0.6756\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7253 - val_loss: 0.6750\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7253 - val_loss: 0.6749\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7252 - val_loss: 0.6759\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7253 - val_loss: 0.6748\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7251 - val_loss: 0.6744\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7250 - val_loss: 0.6744\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7251 - val_loss: 0.6751\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7250 - val_loss: 0.6754\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 5s 2ms/step - loss: 0.7250 - val_loss: 0.6747\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7250 - val_loss: 0.6746\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7249 - val_loss: 0.6753\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7249 - val_loss: 0.6758\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7248 - val_loss: 0.6742\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7247 - val_loss: 0.6748\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7247 - val_loss: 0.6763\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7247 - val_loss: 0.6753\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7247 - val_loss: 0.6748\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7246 - val_loss: 0.6736\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7247 - val_loss: 0.6751\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 3ms/step - loss: 0.7121 - val_loss: 0.6741\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7118 - val_loss: 0.6741\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7118 - val_loss: 0.6746\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7118 - val_loss: 0.6737\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7118 - val_loss: 0.6741\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7117 - val_loss: 0.6731\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7116 - val_loss: 0.6738\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7117 - val_loss: 0.6738\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7116 - val_loss: 0.6735\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7117 - val_loss: 0.6741\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7115 - val_loss: 0.6736\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 5s 2ms/step - loss: 0.7115 - val_loss: 0.6746\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7115 - val_loss: 0.6741\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7113 - val_loss: 0.6730\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7115 - val_loss: 0.6746\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7114 - val_loss: 0.6732\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7113 - val_loss: 0.6739\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7113 - val_loss: 0.6737\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7113 - val_loss: 0.6742\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7113 - val_loss: 0.6733\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 3ms/step - loss: 0.7026 - val_loss: 0.6736\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7025 - val_loss: 0.6747\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7024 - val_loss: 0.6736\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7024 - val_loss: 0.6725\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7023 - val_loss: 0.6745\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7023 - val_loss: 0.6736\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7024 - val_loss: 0.6755\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7022 - val_loss: 0.6735\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7021 - val_loss: 0.6730\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7022 - val_loss: 0.6733\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7021 - val_loss: 0.6734\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7023 - val_loss: 0.6738\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7022 - val_loss: 0.6731\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7021 - val_loss: 0.6734\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7021 - val_loss: 0.6739\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7020 - val_loss: 0.6726\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7020 - val_loss: 0.6730\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7020 - val_loss: 0.6738\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 5s 2ms/step - loss: 0.7020 - val_loss: 0.6736\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7019 - val_loss: 0.6734\n",
      "Train on 2470 samples, validate on 2470 samples\n",
      "Epoch 1/20\n",
      "2470/2470 [==============================] - 6s 3ms/step - loss: 0.7188 - val_loss: 0.6727\n",
      "Epoch 2/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7186 - val_loss: 0.6731\n",
      "Epoch 3/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7185 - val_loss: 0.6729\n",
      "Epoch 4/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7185 - val_loss: 0.6719\n",
      "Epoch 5/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7185 - val_loss: 0.6721\n",
      "Epoch 6/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7184 - val_loss: 0.6733\n",
      "Epoch 7/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7185 - val_loss: 0.6736\n",
      "Epoch 8/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7184 - val_loss: 0.6722\n",
      "Epoch 9/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7184 - val_loss: 0.6728\n",
      "Epoch 10/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7183 - val_loss: 0.6724\n",
      "Epoch 11/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7184 - val_loss: 0.6725\n",
      "Epoch 12/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7183 - val_loss: 0.6734\n",
      "Epoch 13/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7182 - val_loss: 0.6732\n",
      "Epoch 14/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7183 - val_loss: 0.6725\n",
      "Epoch 15/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7182 - val_loss: 0.6724\n",
      "Epoch 16/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7181 - val_loss: 0.6719\n",
      "Epoch 17/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7182 - val_loss: 0.6730\n",
      "Epoch 18/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7181 - val_loss: 0.6730\n",
      "Epoch 19/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7182 - val_loss: 0.6723\n",
      "Epoch 20/20\n",
      "2470/2470 [==============================] - 4s 2ms/step - loss: 0.7182 - val_loss: 0.6725\n",
      "[[0.72009586 0.05539173 0.13092157 0.09359085]\n",
      " [0.08513864 0.67454333 0.13020069 0.11011734]\n",
      " [0.10721871 0.06766595 0.73738333 0.087732  ]\n",
      " [0.11385064 0.09366564 0.13161425 0.66086946]]\n"
     ]
    }
   ],
   "source": [
    "f = open('results/'+result_name,'a')\n",
    "print(\"k: %d assumed_delta: %.2f\"%(k,assumed_delta))\n",
    "\n",
    "ICE_N_DUDE = ICE_Process(n, k, nb_x_classes, nb_z_classes, x, z, param_name = param_name)\n",
    "Estimated_PI, train_loss, val_loss = ICE_N_DUDE.ICE(assumed_PI, PI_true)\n",
    "print(Estimated_PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.718547298309774, 0.774111480365398, 0.7396645883799564, 0.7552730852293099, 0.7386023488121959, 0.7469703310896993, 0.7246565194747708, 0.7112910621561985, 0.7019372434751225, 0.7182151507269515]\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7116511434195978, 0.6772808345223246, 0.6788141081207677, 0.6760887978047977, 0.6766242048518378, 0.674336964060903, 0.6750607492470065, 0.6732962322138581, 0.6734274814003393, 0.6724951380660177]\n"
     ]
    }
   ],
   "source": [
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
