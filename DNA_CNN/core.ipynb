{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/DNA_CNN/Denoising\n",
    "\n",
    "from tools import *\n",
    "import numpy as np\n",
    "import sys\n",
    "from keras import utils\n",
    "import tensorflow as tf\n",
    "import keras as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/DNA_CNN/Denoising\n",
    "\n",
    "class ICE_Process:\n",
    "    def __init__(self, n, k, nb_x_classes, nb_z_classes, x, z, param_name = 'test'):\n",
    "        self.n, self.k, self.x, self.z, self.nb_x_classes, self.nb_z_classes = n, k, x, z, nb_x_classes, nb_z_classes\n",
    "        self.param_name = param_name\n",
    "        self.raw_error = error_rate(x,z)\n",
    "        self.C = make_batch(z,k)\n",
    "    \n",
    "    def Approximate_E_step(self, pred_prob): # approximate E-step & M-step\n",
    "        n, k, z, nb_x_classes, nb_z_classes = self.n, self.k, self.z, self.nb_x_classes, self.nb_z_classes\n",
    "        \n",
    "        \"\"\"\n",
    "        gamma[t][j] = p(x_t = j|Z_t,C_t;w)\n",
    "        \"\"\"\n",
    "        \n",
    "        # approximate E-step\n",
    "        \n",
    "        gamma = np.zeros((n, nb_x_classes))\n",
    "        for i in range(nb_x_classes):\n",
    "            gamma[:,i] = pred_prob[:,i+1]\n",
    "        gamma[np.arange(n), z] += pred_prob[np.arange(n), 0]\n",
    "        return gamma\n",
    "        \n",
    "    def M_step(self, pred_prob):\n",
    "        n, k, z, nb_x_classes, nb_z_classes = self.n, self.k, self.z, self.nb_x_classes, self.nb_z_classes\n",
    "        \n",
    "        gamma = self.Approximate_E_step(pred_prob)\n",
    "        \n",
    "        # M-step\n",
    "        PI = np.zeros((nb_x_classes, nb_z_classes))\n",
    "        np.add.at(PI.T, z, gamma)\n",
    "        PI /= (np.sum(gamma, axis = 0).reshape(nb_x_classes,1) + 1e-35)\n",
    "        return PI\n",
    "    \n",
    "    def ICE(self, PI): # Iterative Channel Estimation Process\n",
    "        n, k, nb_x_classes, nb_z_classes, z, param_name, C = self.n, self.k, self.nb_x_classes, self.nb_z_classes, self.z, self.param_name, self.C\n",
    "        iteration = 3\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            # reset the L_new matrix\n",
    "            L_new = L_NEW(PI, nb_x_classes, nb_z_classes)\n",
    "            Y = make_pseudo_label(C, k, L_new)\n",
    "            model = NDUDE_CNN_model_5map(1000, nb_x_classes, nb_z_classes, k)\n",
    "            \n",
    "            # from second iteration, load previous weights and reset the learning rate.\n",
    "            if t!=0:\n",
    "                model.load_weights(\"weights/iteration/\"+param_name+\"_%d.hd5\"%(t-1))\n",
    "            \n",
    "            # model training...\n",
    "            hist = model.fit(C,Y,epochs=20, batch_size=2*4, verbose=1, validation_data=(C, Y))\n",
    "            pred_prob = model.predict(C, batch_size = 20*4, verbose = 0)\n",
    "            \n",
    "            # resize the output\n",
    "            N,D,_ = pred_prob.shape\n",
    "            pred_prob = np.resize(pred_prob, (N*D,nb_x_classes+1))[:n]\n",
    "            \n",
    "            # estimate the channel\n",
    "            PI = self.M_step(pred_prob)\n",
    "            \n",
    "            # save weights for next iteration\n",
    "            model.save_weights(\"weights/iteration/\"+param_name+\"_%d.hd5\"%(t))\n",
    "            \n",
    "            # save weights for denoising process\n",
    "            if t == iteration-1:\n",
    "                model.save_weights(\"weights/\"+param_name+\".hd5\")\n",
    "                save_PI(PI, param_name)\n",
    "        return PI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/DNA_CNN/Denoising\n",
    "\n",
    "class Denoising_Process:\n",
    "    def __init__(self, n, k, nb_x_classes, nb_z_classes, x, z, param_name = 'test'):\n",
    "        self.n, self.k, self.x, self.z, self.nb_x_classes, self.nb_z_classes = n, k, x, z, nb_x_classes, nb_z_classes\n",
    "        self.param_name = param_name\n",
    "        self.raw_error = error_rate(x,z)\n",
    "        self.C = make_batch(z,k)\n",
    "    \n",
    "    def denoise(self, pred_prob): # Denoise sequence using softmax output\n",
    "        n, k, x, z = self.n, self.k, self.x, self.z\n",
    "        \n",
    "        \"\"\"\n",
    "        pred_class[0] = Say What You See(s[0]=z[i]) = -1\n",
    "        pred_class[1] = Always Say 0(s[1]=0) = 0\n",
    "        pred_class[2] = Always Say 1(s[2]=1) = 1\n",
    "        pred_class[3] = Always Say 1(s[2]=1) = 2\n",
    "        pred_class[4] = Always Say 1(s[2]=1) = 3\n",
    "        \"\"\"\n",
    "        \n",
    "        # s(z) = z\n",
    "        pred_class = np.argmax(pred_prob, axis = -1) - 1\n",
    "        \n",
    "        # mask Say What You see\n",
    "        mask = pred_class == -1\n",
    "        \n",
    "        # mask-> Say What You see || others-> 0,1,2,3\n",
    "        x_hat = z * mask + (mask^1)*pred_class\n",
    "\n",
    "        error = normalized_error_rate(x,x_hat,self.raw_error)\n",
    "        return error, x_hat\n",
    "    \n",
    "    def N_DUDE(self, PI): # Denoising process\n",
    "        n, k, nb_x_classes, nb_z_classes, z, param_name, C = self.n, self.k, self.nb_x_classes, self.nb_z_classes, self.z, self.param_name, self.C\n",
    "        \n",
    "        \n",
    "        # fine-tuning the weights from ICE process\n",
    "        L_new = L_NEW(PI, nb_x_classes, nb_z_classes)\n",
    "        Y = make_pseudo_label(C, k, L_new)\n",
    "        \n",
    "        # model assign & train\n",
    "        if param_name == 'NDUDE':\n",
    "            model = NDUDE_CNN_model_5map(1000, nb_x_classes, nb_z_classes, k)\n",
    "            hist = model.fit(C,Y,epochs=20, batch_size=2*4, verbose=1, validation_data=(C, Y))\n",
    "        \n",
    "        else:\n",
    "            model = NDUDE_CNN_model_5map(1000, nb_x_classes, nb_z_classes, k, lr = 0.0001)\n",
    "            model.load_weights(\"weights/\"+param_name+\".hd5\")\n",
    "            hist = model.fit(C,Y,epochs=10, batch_size=2*4, verbose=1, validation_data=(C, Y))\n",
    "            \n",
    "        pred_prob = model.predict(C, batch_size = 20*4, verbose = 0)\n",
    "        \n",
    "        # reshape the output\n",
    "        N,D,_ = pred_prob.shape\n",
    "        pred_prob = np.resize(pred_prob, (N*D,nb_x_classes+1))[:n]\n",
    "        \n",
    "        return self.denoise(pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/DNA_CNN/Denoising\n",
    "\n",
    "class BW_1st_channel:\n",
    "    def __init__(self, n, nb_classes, x, z, param_name = 'test'):\n",
    "        self.n = n\n",
    "        self.nb_classes = nb_classes\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.param_name = param_name\n",
    "        self.raw_error = error_rate(x,z)\n",
    "    def denoise(self, gamma):\n",
    "        # use bayes response\n",
    "        x_hat = np.argmax(gamma[1:], axis = 1)\n",
    "        normalized_error = normalized_error_rate(x_hat, self.x, self.raw_error)\n",
    "        return normalized_error, x_hat\n",
    "    \n",
    "    def Baum_Welch(self, TRANS, PI):\n",
    "        n, nb_classes, z, param_name = self.n, self.nb_classes, self.z, self.param_name\n",
    "        \n",
    "        pi = np.ones(nb_classes) / float(nb_classes)\n",
    "        \n",
    "        a = np.copy(TRANS)\n",
    "        b = np.copy(PI)\n",
    "        \n",
    "        T = z.shape[0]\n",
    "        hid_states = a.shape[0]\n",
    "        obs_states = b.shape[1]\n",
    "        gamma = None\n",
    "        delta = None\n",
    "        p = None\n",
    "        #while True:\n",
    "        for i in range(40):\n",
    "            xi = np.zeros((T+1, 2, hid_states))\n",
    "            gamma = np.zeros((T+1, hid_states))\n",
    "            joint = np.zeros((T+1, hid_states, hid_states))\n",
    "\n",
    "            for t in range(1,T+1): # 1~T\n",
    "                eta = b[:, z[t-1]]\n",
    "                if t==1:\n",
    "                    xi[t][0] = pi\n",
    "                else:\n",
    "                    xi[t][0] = np.matmul(xi[t-1][1], a)\n",
    "                xi[t][1] = (eta * xi[t][0]) / (np.sum(eta * xi[t][0]) + 1e-35)\n",
    "\n",
    "            gamma[T] = xi[T][1]\n",
    "            for t in reversed(range(1,T)):\n",
    "                gamma[t] = xi[t][1] * np.matmul(gamma[t+1] / (xi[t+1][0]) + 1e-35, a.T)\n",
    "                joint[t] = xi[t][1].reshape(hid_states,1) * (gamma[t+1] / (xi[t+1][0] + 1e-35)) * a\n",
    "\n",
    "\n",
    "            a_before = a\n",
    "            b_before = b\n",
    "            pi = gamma[1]\n",
    "            a = np.sum(joint[1:T], axis = 0) / (np.sum(gamma[1:T], axis = 0).reshape(hid_states,1) + 1e-35)\n",
    "\n",
    "            b = b * 0\n",
    "            np.add.at(b.T, z, gamma[1:])\n",
    "            b /= (np.sum(gamma, axis = 0).reshape(hid_states,1) + 1e-35)\n",
    "\n",
    "\n",
    "            if rel_error(a, a_before) < 1e-6 and rel_error(b, b_before) < 1e-6:\n",
    "                break\n",
    "        \n",
    "        save_PI(b, param_name)\n",
    "        return a, b, gamma\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/DNA_CNN/Denoising\n",
    "\n",
    "class BW_2nd_channel:\n",
    "    def __init__(self, n, nb_classes, x, z, param_name = 'test'):\n",
    "        self.n = n\n",
    "        self.nb_classes = nb_classes\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.param_name = param_name\n",
    "        self.raw_error = error_rate(x,z)\n",
    "    def denoise(self, gamma):\n",
    "        # use bayes response\n",
    "        x_hat = np.argmax(gamma[1:], axis = 1)\n",
    "        normalized_error = normalized_error_rate(x_hat%4, self.x%4, self.raw_error)\n",
    "        return normalized_error, x_hat\n",
    "    \n",
    "    def Baum_Welch(self, TRANS, PI):\n",
    "        n, nb_classes, z, param_name = self.n, self.nb_classes, self.z, self.param_name\n",
    "        \n",
    "        pi = np.ones(nb_classes*nb_classes) / float(nb_classes*nb_classes)\n",
    "        \n",
    "        a = np.copy(TRANS)\n",
    "        b = np.copy(PI)\n",
    "        \n",
    "        T = z.shape[0]\n",
    "        hid_states = a.shape[0]\n",
    "        obs_states = b.shape[1]\n",
    "        gamma = None\n",
    "        delta = None\n",
    "        p = None\n",
    "        #while True:\n",
    "        for i in range(40):\n",
    "            xi = np.zeros((T+1, 2, hid_states))\n",
    "            gamma = np.zeros((T+1, hid_states))\n",
    "            joint = np.zeros((T+1, hid_states, hid_states))\n",
    "\n",
    "            for t in range(1,T+1): # 1~T\n",
    "                eta = b[:, z[t-1]]\n",
    "                if t==1:\n",
    "                    xi[t][0] = pi\n",
    "                else:\n",
    "                    xi[t][0] = np.matmul(xi[t-1][1], a)\n",
    "                xi[t][1] = (eta * xi[t][0]) / (np.sum(eta * xi[t][0]) + 1e-35)\n",
    "\n",
    "            gamma[T] = xi[T][1]\n",
    "            for t in reversed(range(1,T)):\n",
    "                gamma[t] = xi[t][1] * np.matmul(gamma[t+1] / (xi[t+1][0]) + 1e-35, a.T)\n",
    "                joint[t] = xi[t][1].reshape(hid_states,1) * (gamma[t+1] / (xi[t+1][0] + 1e-35)) * a\n",
    "\n",
    "            \n",
    "            \n",
    "            # marginalize the channel\n",
    "            b_hat = np.zeros((obs_states, obs_states))\n",
    "            gamma_hat = np.zeros((T+1, obs_states))\n",
    "            for i in range(obs_states):\n",
    "                arr = np.zeros(T+1)\n",
    "                for j in range(obs_states):\n",
    "                    arr += gamma[:,i+j*obs_states]\n",
    "                gamma_hat[:,i] = arr\n",
    "\n",
    "            np.add.at(b_hat.T, z, gamma_hat[1:])\n",
    "            b_hat /= (np.sum(gamma_hat, axis = 0).reshape(obs_states,1) + 1e-35)\n",
    "            \n",
    "            \n",
    "            a_before = a\n",
    "            b_before = b\n",
    "            pi = gamma[1]\n",
    "            a = np.sum(joint[1:T], axis = 0) / (np.sum(gamma[1:T], axis = 0).reshape(hid_states,1) + 1e-35)\n",
    "\n",
    "            b = b * 0\n",
    "            np.add.at(b.T, z, gamma[1:])\n",
    "            b /= (np.sum(gamma, axis = 0).reshape(hid_states,1) + 1e-35)\n",
    "\n",
    "\n",
    "            if rel_error(a, a_before) < 1e-6 and rel_error(b, b_before) < 1e-6:\n",
    "                break\n",
    "        \n",
    "        save_PI(b_hat, param_name)\n",
    "        return a, b_hat, gamma_hat\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
