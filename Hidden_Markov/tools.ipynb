{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras import layers, optimizers, models, utils\n",
    "from keras.layers import Input, Dense, Activation, Add\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "\n",
    "from keras.engine.topology import Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def error_rate(a,b):\n",
    "    error = absolute(a-b) > 0\n",
    "    return np.mean(error)\n",
    "\n",
    "def normalized_error_rate(a,b,raw_error):\n",
    "    error = absolute(a-b) > 0\n",
    "    return np.mean(error) / raw_error\n",
    "\n",
    "def rel_error(x, y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def L_NEW(PI, nb_x_classes, nb_z_classes):\n",
    "    PI_INV = linalg.inv(PI)\n",
    "    RHO = np.zeros((nb_x_classes, nb_x_classes+1))\n",
    "    LAMBDA = np.ones((nb_x_classes, nb_x_classes)) - np.eye(nb_x_classes)\n",
    "\n",
    "    MAP = np.ones((nb_x_classes, nb_x_classes+1), dtype = int)\n",
    "\n",
    "    for x in range(nb_x_classes):\n",
    "        for s in range(nb_x_classes+1):\n",
    "            MAP[x][s] = s - 1\n",
    "            MAP[x][0] = x\n",
    "\n",
    "    for x in range(nb_x_classes):\n",
    "        for s in range(nb_x_classes+1):\n",
    "            for z in range(nb_z_classes):\n",
    "                RHO[x][s] += PI[x][z] * LAMBDA[x][MAP[z][s]]\n",
    "\n",
    "    L = np.matmul(PI_INV, RHO)\n",
    "    L_new = -L + amax(L)\n",
    "    return L_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def load_PI(name):\n",
    "    hdf5_path = 'PI/'+name+'.hdf5'\n",
    "    hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "    PI = hdf5_file[name][...]\n",
    "    hdf5_file.close()\n",
    "    return PI\n",
    "\n",
    "def save_PI(PI, name):\n",
    "    hdf5_path = 'PI/'+name+'.hdf5'\n",
    "    hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "    hdf5_file.create_dataset(name, PI.shape, np.float32, data = PI)\n",
    "    hdf5_file.close()\n",
    "\n",
    "def load_channel(true_or_assumed, nb_x_classes, order, PI_type_num):\n",
    "    PI_dict = sio.loadmat('PARAM/' + true_or_assumed + '_PI.mat')\n",
    "    PI = PI_dict['%d_%d_%d'%(nb_x_classes, order, PI_type_num)]\n",
    "    return PI\n",
    "\n",
    "def load_TRANS(true_or_assumed, nb_x_classes, order):\n",
    "    TRANS_dict = sio.loadmat('PARAM/' + true_or_assumed + '_TRANS.mat')\n",
    "    TRANS = TRANS_dict['%d_%d'%(nb_x_classes, order)]\n",
    "    return TRANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def sym_mat(states, prob):\n",
    "    x = ones((states,states)) * (prob/(states-1))\n",
    "    for i in range(states):\n",
    "        x[i][i] = 1 - (states-1)*x[i][i]\n",
    "    return x\n",
    "\n",
    "def convert_sequence(x, order, nb_x_classes):\n",
    "    if order == 1:\n",
    "        return x\n",
    "    x_temp = np.copy(x)\n",
    "    x_temp = np.hstack((np.zeros(order-1), x_temp))\n",
    "    n = len(x)\n",
    "    mask = np.ones((order))\n",
    "    x_convert = np.zeros(n, dtype = int)\n",
    "    for i in range(order):\n",
    "        mask[i] = nb_x_classes ** (order-i-1)    \n",
    "    \n",
    "    for i in range(n):\n",
    "        x_convert[i] = np.dot(mask, x_temp[i:i+order])\n",
    "    \n",
    "    return x_convert\n",
    "\n",
    "def make_context(z, k, nb_z_classes, n):\n",
    "    Z = utils.np_utils.to_categorical(z,nb_z_classes)\n",
    "    c_length=2*k\n",
    "    C=zeros((n-2*k, 2*k*nb_z_classes))\n",
    "\n",
    "    for i in range(k,n-k):\n",
    "        c_i = vstack((Z[i-k:i,],Z[i+1:i+k+1,])).reshape(1,2*k*nb_z_classes)\n",
    "        C[i-k,]=c_i\n",
    "        \n",
    "    return C\n",
    "\n",
    "def make_pseudo_label(z, k, L_new, nb_z_classes, n):\n",
    "    Z = utils.np_utils.to_categorical(z, nb_z_classes)\n",
    "    Y = dot(Z[k:n-k],L_new)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def Hidden_Markov(n, a, b):\n",
    "    x, z = np.zeros(n, dtype = np.int), np.zeros(n, dtype = np.int)\n",
    "    hid_states, obs_states = a.shape[0], b.shape[1]\n",
    "    a_sum = np.copy(a)\n",
    "    b_sum = np.copy(b)\n",
    "\n",
    "    for i in range(1,hid_states):\n",
    "        a_sum.T[i] += a_sum.T[i-1]\n",
    "    for i in range(1,obs_states):\n",
    "        b_sum.T[i] += b_sum.T[i-1]\n",
    "    \n",
    "    \n",
    "    prob = np.random.random()\n",
    "    x[0] = int(prob/(1 / float(hid_states)))\n",
    "    prob = np.random.random()\n",
    "    z[0] = np.argmax(b_sum[x[0]] > prob)\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        prob = np.random.random()\n",
    "        x[i] = np.argmax(a_sum[x[i-1]] > prob)\n",
    "        prob = np.random.random()\n",
    "        z[i] = np.argmax(b_sum[x[i]] > prob)\n",
    "    return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def dude(z, k, nb_x_classes, nb_z_classes, PI):\n",
    "    n=len(z)\n",
    "    x_hat=np.zeros(n,dtype=np.int)\n",
    "    m={}\n",
    "    PI_INV = linalg.inv(PI)\n",
    "    LAMBDA = np.ones((nb_x_classes, nb_x_classes)) - np.eye(nb_x_classes)\n",
    "    for i in range(k,n-k):\n",
    "        context=z[i-k:i].tolist()+z[i+1:i+k+1].tolist()\n",
    "        context_str = ''.join(str(e) for e in context)\n",
    "        \n",
    "        if context_str not in m:\n",
    "            m[context_str]=np.zeros(nb_z_classes,dtype=np.int)\n",
    "            m[context_str][z[i]]=1\n",
    "        else:\n",
    "            m[context_str][z[i]]+=1\n",
    "    x_hat[:k] = z[:k]\n",
    "    x_hat[n-k:n] = z[n-k:n]\n",
    "    for i in range(k,n-k):\n",
    "        context=z[i-k:i].tolist()+z[i+1:i+k+1].tolist()\n",
    "        context_str = ''.join(str(e) for e in context)\n",
    "        m_vector = m[context_str]\n",
    "        EXP = np.dot(PI_INV, LAMBDA * (PI[:,z[i]].reshape((nb_x_classes,1))))\n",
    "        score = np.dot(m_vector, EXP)\n",
    "        x_hat[i] = np.argmin(score)\n",
    "    \n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def FB_recursion(a, b, z, denoise = True):\n",
    "    \n",
    "    T = z.shape[0]\n",
    "    hid_states = a.shape[0]\n",
    "    obs_states = b.shape[1]\n",
    "    xi = np.zeros((T+1, 2, hid_states))\n",
    "    gamma = np.zeros((T+1, hid_states))\n",
    "    \n",
    "    pi = np.ones(hid_states) / float(hid_states)\n",
    "    \n",
    "    for t in range(1,T+1): # 1~T\n",
    "        eta = b[:, z[t-1]]\n",
    "        if t==1:\n",
    "            xi[t][0] = pi\n",
    "        else:\n",
    "            xi[t][0] = np.matmul(xi[t-1][1], a)    \n",
    "        xi[t][1] = (eta * xi[t][0]) / (np.sum(eta * xi[t][0]) + 1e-35)\n",
    "        \n",
    "    gamma[T] = xi[T][1]\n",
    "    for t in reversed(range(1,T)):\n",
    "        gamma[t] = xi[t][1] * np.matmul(gamma[t+1] / (xi[t+1][0] + 1e-35) , a.T)\n",
    "    \n",
    "    if denoise == False:\n",
    "        return gamma\n",
    "    #denoise the sequence\n",
    "    x_hat = np.argmax(gamma[1:], axis = 1)\n",
    "\n",
    "    return x_hat, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML_2019/Hidden_Markov/Denoising\n",
    "\n",
    "def ICE_N_DUDE_model(nb_x_classes, nb_z_classes, k, lr = 0.001):\n",
    "    unitN = 20 * nb_z_classes\n",
    "    with tf.device('/cpu:0'):\n",
    "        \n",
    "        inputs = Input(shape=(2*k*nb_z_classes,))\n",
    "        layer = layers.Dense(unitN)(inputs)\n",
    "        layer = layers.Activation('relu')(layer)\n",
    "        layer = layers.Dense(unitN)(layer)\n",
    "        layer = layers.Activation('relu')(layer)\n",
    "        layer = layers.Dense(unitN)(layer)\n",
    "        layer = layers.Activation('relu')(layer)\n",
    "        layer = layers.Dense(nb_x_classes+1)(layer)\n",
    "        output = layers.Activation('softmax')(layer)\n",
    "        model = models.Model(inputs = inputs, outputs = output)\n",
    "    \n",
    "    adam = optimizers.Adam(lr=lr)\n",
    "    multi_model = multi_gpu_model(model, gpus=4)\n",
    "    multi_model.compile(loss='poisson', optimizer=adam)\n",
    "    return multi_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
